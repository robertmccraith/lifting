\documentclass[]{article}
\usepackage[nonatbib]{neurips_2021}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{color}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{makecell}
\usepackage{microtype}
\usepackage{multirow,makecell}
\usepackage{nicefrac}
\usepackage{subcaption}
\usepackage{url}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{xcolor,colortbl}
\usepackage{pgfplots}
\input{vedaldi}
\pgfplotsset{compat=1.17}

% No space paragraph.
\makeatletter
\renewcommand{\paragraph}{%
  \@startsection{paragraph}{4}%
  %{\z@}{3.25ex \@plus 1ex \@minus .2ex}{-1em}%
  {\z@}{0em}{-1em}%
  {\normalfont\normalsize\bfseries}%
}
\makeatother

% \DeclareMathOperator{\front_con}{Consistency_{front}}
% \DeclareMathOperator{\centre_con}{Consistency_{centre}}
% \DeclareMathOperator{\amin}{argmin}

% \title{Weakly-supervised 3D Object Detection by Automated Outlier Exclusion and Multi-View Consistency}
\title{Lifting 2D Object Locations to 3D by Discounting LiDAR Outliers across Objects and Views}
% \title{}
% \title{Lifting 2D Detections to 3D locations across multiple views}


\author{%
  David S.~Hippocampus\thanks{Use footnote for providing further information
    about author (webpage, alternative address)---\emph{not} for acknowledging
    funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}
\maketitle

\begin{abstract}
We present a system for automatic converting of 2D mask object predictions and raw LiDAR point clouds into full 3D bounding boxes of objects.
Because the LiDAR point clouds are partial, directly fitting bounding boxes to the point clouds is meaningless.
Instead, we suggest that obtaining good results requires sharing information between \emph{all} objects in the dataset jointly, over multiple frames.
We then make three improvements to the baseline.
First, we address ambiguities in predicting the object rotations via direct optimization in this space while still backpropagating rotation prediction through the model.
Second, we explicitly model outliers and task the network with learning their typical patterns, thus better discounting them.
Third, we enforce temporal consistency when video data is available.
With these contributions, our method significantly outperforms previous work despite the fact that these use significantly more complex pipelines, 3D models and additional human-annotated external sources of prior information.
% We propose a new direct optimization of the object rotations, fixing the ambiguity of the rotation estimation.
% Localising objects in 3D is a fundamental requirement of many robotic systems. This task requires a large amount of annotated training data which is expensive to obtain and of questionable accuracy for some objects. In contrast 2D annotations are much simpler to obtain and train as has been shown in many recent works. In this work we propose a method which allows the use of a pre-trained 2D instance segmentation network to train a 3D object detection network without the need for expensive 3D annotations. The main contributions of our method are as follows: 1) automatic segmentation of raw LiDAR data by learning to remove outlier points during training 2) novel training scheme that avoids local optima in viewpoint estimation 3) learning across multiple frames that enforces temporal consistency of the scene. Our method significantly outperforms previous yet more complex methods while also requiring less supervision for training.
%The method automatically segments raw LiDAR data by learning to remove outlier points during training and by combining it with novel training scheme which avoids local optima and with enforcing scene consistency between multiple frames, the method significantly outperforms previous yet more complex methods.
\end{abstract}

\input{intro}
\input{related}
\input{method}
\input{experiments}
\input{conclusions}
\input{broaderimpact}

{\small \bibliographystyle{plain}\bibliography{mccraith_g,vedaldi_general,vedaldi_specific, insafutdinov}}

\section*{Checklist}

%%% BEGIN INSTRUCTIONS %%%
The checklist follows the references.  Please
read the checklist guidelines carefully for information on how to answer these
questions.  For each question, change the default \answerTODO{} to \answerYes{},
\answerNo{}, or \answerNA{}.  You are strongly encouraged to include a {\bf
justification to your answer}, either by referencing the appropriate section of
your paper or providing a brief inline description.  For example:
\begin{itemize}
  \item Did you include the license to the code and datasets? \answerYes{See Section~\ref{gen_inst}.}
  \item Did you include the license to the code and datasets? \answerNo{The code and the data are proprietary.}
  \item Did you include the license to the code and datasets? \answerNA{}
\end{itemize}
Please do not modify the questions and only use the provided macros for your
answers.  Note that the Checklist section does not count towards the page
limit.  In your paper, please delete this instructions block and only keep the
Checklist section heading above along with the questions/answers below.
%%% END INSTRUCTIONS %%%

\begin{enumerate}

\item For all authors...
\begin{enumerate}
  \item Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?
    \answerYes{}
  \item Did you describe the limitations of your work?
    \answerYes{sec.~\ref{s:broaderimpact}}
  \item Did you discuss any potential negative societal impacts of your work?
    \answerYes{sec.~\ref{s:broaderimpact}}
  \item Have you read the ethics review guidelines and ensured that your paper conforms to them?
    \answerYes{}
\end{enumerate}

\item If you are including theoretical results...
\begin{enumerate}
  \item Did you state the full set of assumptions of all theoretical results?
    \answerNA{}
	\item Did you include complete proofs of all theoretical results?
    \answerNA{}
\end{enumerate}

\item If you ran experiments...
\begin{enumerate}
  \item Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?
    \answerYes{}
  \item Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?
    \answerYes{see sec.~\ref{s:expsetup}}
	\item Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?
    \answerYes{}
	\item Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?
    \answerYes{see sec.~\ref{s:expsetup}}
\end{enumerate}

\item If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
\begin{enumerate}
  \item If your work uses existing assets, did you cite the creators?
    \answerYes{see sec.~\ref{s:expsetup}}
  \item Did you mention the license of the assets?
    \answerYes{see sec.~\ref{s:expsetup}}
  \item Did you incimude any new assets either in the supplemental material or as a URL?
    \answerNo{}
  \item Did you discuss whether and how consent was obtained from people whose data you're using/curating?
    \answerNA{The dataset used in this work is released into public by its creators and available for research purposes.}
  \item Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content?
    \answerYes{see sec.~\ref{s:experiments}}
\end{enumerate}

\item If you used crowdsourcing or conducted research with human subjects...
\begin{enumerate}
  \item Did you include the full text of instructions given to participants and screenshots, if applicable?
    \answerNA{}
  \item Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?
    \answerNA{}
  \item Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?
    \answerNA{}
\end{enumerate}

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\end{document}